{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow\n",
    "! pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.python.lib.io.tf_record import TFRecordWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of sample pass to the train and test as example\n",
    "SAMPLE_FRAC = 0.2\n",
    "# 80% data for training and 20% data for validate\n",
    "TRAIN_FRAC = 0.8\n",
    "\n",
    "# load train data from train.csv\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train.reset_index(inplace=True)\n",
    "# change sentiment label form 'pos' and 'neg' to 1 and 0, which bert model knows\n",
    "train['sentiment'].replace({'pos':1,'neg':0},inplace=True)\n",
    "\n",
    "# train set\n",
    "train_sample = train.sample(frac=SAMPLE_FRAC,random_state=0)\n",
    "train_select = train_sample.sample(frac= TRAIN_FRAC,random_state=0)\n",
    "train_csv = train_select.values\n",
    "\n",
    "# validate set \n",
    "validate_select = train_sample.drop(index=train_select.index)\n",
    "validate_csv = validate_select.values\n",
    "\n",
    "\n",
    "# load test data , here should be validation set\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test.reset_index(inplace=True)\n",
    "test['sentiment'].replace({'pos':1,'neg':0},inplace=True)\n",
    "test_csv = test.sample(frac=SAMPLE_FRAC,random_state=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def create_tf_example(features,label):\n",
    "    \"\"\"\n",
    "    Create tf example using features and label\n",
    "\n",
    "    Args:\n",
    "        features: list, feature list with format  ['idx','sentence']\n",
    "        label: string, \n",
    "\n",
    "    Return:\n",
    "        A binary-string of tf example.\n",
    "        All proto messages can be serialized to a binary-string using the .SerializeToString method.\n",
    "    \"\"\"\n",
    "    tf_example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "        'idx': tf.train.Feature(int64_list=tf.train.Int64List(value=[features[0]])),\n",
    "        'sentence': tf.train.Feature(bytes_list=tf.train.BytesList(value=[features[1].encode('utf-8')])),\n",
    "        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    }))\n",
    "    return tf_example.SerializeToString()\n",
    "\n",
    "def convert_csv_to_tfrecord(csv, file_name):\n",
    "    \"\"\"\n",
    "    Convert the numpy arryes to tfrecord and write files\n",
    "\n",
    "    Args:\n",
    "        csv: numpy arrays, each row feed (features+label)\n",
    "        file_name: location TFRecord to be saved \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    writer = TFRecordWriter(file_name)\n",
    "    for idx,row in enumerate(csv):\n",
    "        # check the row retionality, raise error when missing value\n",
    "        try:\n",
    "            if row is None:\n",
    "                raise Exception('Row Missing')\n",
    "            if row[0] is None or row[1] is None or row[2] is None:\n",
    "                raise Exception('Value Missing')\n",
    "            if row[1].strip() is '':\n",
    "                raise Exception('Utterance is empty')\n",
    "            \n",
    "            features, label = row[:-1],row[-1]\n",
    "            example =  create_tf_example(features,label)\n",
    "            writer.write(example)\n",
    "\n",
    "        except Exception as inst:\n",
    "            print(type(inst))\n",
    "            print(inst.args)\n",
    "            print(inst)\n",
    "    writer.close()\n",
    "    print(f\"{file_name}: --- {(time.time() - start_time)} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_csv_to_tfrecord(train_csv, \"data/movie_train.tfrecord\") \n",
    "convert_csv_to_tfrecord(validate_csv, \"data/movie_validate.tfrecord\") \n",
    "convert_csv_to_tfrecord(test_csv, \"data/movie_test.tfrecord\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# generate exmaple number , save for use in the future \n",
    "def generate_json_info(local_file_name,df_train=[],df_val=[],df_test=[]):\n",
    "    info = {\"train_length\": len(df_train), \"validation_length\": len(df_val),\n",
    "            \"test_length\": len(df_test)}\n",
    "\n",
    "    with open(local_file_name, 'w') as outfile:\n",
    "        json.dump(info, outfile)\n",
    "\n",
    "generate_json_info('data/info.json',train_csv,validate_csv,test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = tf.data.TFRecordDataset(\"data/movie_train.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_spec = {\n",
    "    'idx': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'sentence': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def parse_example(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_spec)\n",
    "tr_parse_ds = tr_ds.map(parse_example)\n",
    "dataset_iterator = iter(tr_parse_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, glue_convert_examples_to_features\n",
    "from transformers.configuration_bert import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = tf.data.TFRecordDataset(\"data/movie_train.tfrecord\")\n",
    "val_ds = tf.data.TFRecordDataset(\"data/movie_validate.tfrecord\")\n",
    "test_ds = tf.data.TFRecordDataset(\"data/movie_test.tfrecord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_spec = {\n",
    "    'idx': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'sentence': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def parse_example(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "# convert the encoded string tensor into the separate tensors that will feed into the model\n",
    "tr_parse_ds = tr_ds.map(parse_example)\n",
    "val_parse_ds = val_ds.map(parse_example)\n",
    "test_parse_ds =  test_ds.map(parse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(features):\n",
    "    revised_sentence = tf.strings.regex_replace(features['sentence'], \"\\.\\.\\.\", \"\", replace_global=True)\n",
    "    revised_sentence = tf.strings.regex_replace(revised_sentence, \"\\\\'\", \"'\", replace_global=True)\n",
    "    revised_sentence = tf.strings.regex_replace(revised_sentence, \"\\\\n\", \"\", replace_global=True)\n",
    "    features['sentence'] = revised_sentence\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_clean_ds = tr_parse_ds.map(lambda features: clean_string(features))\n",
    "val_clean_ds = val_parse_ds.map(lambda features: clean_string(features))\n",
    "test_clean_ds =  test_parse_ds.map(lambda features: clean_string(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "EVAL_BATCH_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "# XLA is the optimizing compiler for machine learning\n",
    "# It can potentially increase speed by 15% with no source code changes\n",
    "USE_XLA = False\n",
    "\n",
    "# mixed precision results on https://github.com/huggingface/transformers/tree/master/examples\n",
    "# Mixed precision can help to speed up training time\n",
    "USE_AMP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(USE_XLA)\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": USE_AMP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps is determined by the number of examples\n",
    "import json\n",
    "with open('data/info.json') as json_file:\n",
    "    data_info = json.load(json_file)\n",
    "    \n",
    "train_examples = data_info['train_length']\n",
    "valid_examples = data_info['validation_length']\n",
    "test_examples = data_info['test_length']\n",
    "\n",
    "train_examples, valid_examples, test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model from pretrained model/vocabulary. Specify the number of labels to classify (2+: classification, 1: regression)\n",
    "num_labels = 2 \n",
    "config = BertConfig.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make use of the following config parameters\n",
    "\n",
    "# {\n",
    "#   \"architectures\": [\n",
    "#     \"BertForMaskedLM\"\n",
    "#   ],\n",
    "#   \"attention_probs_dropout_prob\": 0.1,\n",
    "#   \"hidden_act\": \"gelu\",\n",
    "#   \"hidden_dropout_prob\": 0.1,\n",
    "#   \"hidden_size\": 768,\n",
    "#   \"initializer_range\": 0.02,\n",
    "#   \"intermediate_size\": 3072,\n",
    "#   \"max_position_embeddings\": 512,\n",
    "#   \"num_attention_heads\": 12,\n",
    "#   \"num_hidden_layers\": 12,\n",
    "#   \"type_vocab_size\": 2,\n",
    "#   \"vocab_size\": 28996\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "train_dataset = glue_convert_examples_to_features(examples=tr_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2',\n",
    "                                                  label_list=['0','1']\n",
    "                                                  )\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "valid_dataset = glue_convert_examples_to_features(examples=val_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2'\n",
    "                                                  , label_list =['0', '1'])\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(train_examples).batch(BATCH_SIZE).repeat(-1)\n",
    "\n",
    "valid_dataset = valid_dataset.batch(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "if USE_AMP:\n",
    "    # loss scaling is currently required when using mixed precision\n",
    "    opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, 'dynamic')\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = train_examples//BATCH_SIZE\n",
    "valid_steps = valid_examples//EVAL_BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU USAGE\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=6, steps_per_epoch=train_steps,\n",
    "                    validation_data=valid_dataset, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "test_dataset = glue_convert_examples_to_features(examples=test_clean_ds, tokenizer=tokenizer\n",
    "                                                  , max_length=512, task='sst-2'\n",
    "                                                  , label_list =['0', '1'])\n",
    "print(f\"---{time.time()-start_time} seconds---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.batch(EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(model.predict(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_argmax = tf.math.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.Variable([], dtype=tf.int64)\n",
    "\n",
    "for features, label in test_dataset.take(-1):\n",
    "    y_true = tf.concat([y_true, label], 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def visualize_confusion_matrix(y_pred_argmax, y_true):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_pred_arg: This is an array with values that are 0 or 1\n",
    "    :param y_true: This is an array with values that are 0 or 1\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    cm = tf.math.confusion_matrix(y_true, y_pred_argmax).numpy()\n",
    "    con_mat_df = pd.DataFrame(cm)\n",
    "    \n",
    "    print(classification_report(y_pred_argmax, y_true))\n",
    "\n",
    "    sns.heatmap(con_mat_df, annot=True, fmt='g', cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "print(classification_report(test_labels, baseline_predicted))\n",
    "visualize_confusion_matrix(y_pred_argmax, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, './202002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = tf.saved_model.load('./202002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {'idx': tf.constant(1, dtype=tf.int64), 'label': tf.constant(0, dtype=tf.int64) ,\n",
    "           'sentence': tf.constant('This is the best store that I have ever visited', dtype=tf.string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensors(example)\n",
    "feature_ds = glue_convert_examples_to_features(ds, tokenizer, max_length=128, task='sst-2')\n",
    "feature_dataset = feature_ds.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(feature_dataset, savedmodel):\n",
    "    \"\"\"\n",
    "    :param feature_dataset: Contains information needed for BERT\n",
    "    :param savedmodel: This is the model that has been pretrained in a sep process.\n",
    "    :return: JSON output with the predicted classification. \n",
    "    \"\"\"\n",
    "    \n",
    "    json_examples = []\n",
    "    for feature_batch in feature_dataset.take(-1):\n",
    "        feature_example = feature_batch[0]\n",
    "\n",
    "        # The SavedModel is going to generate log probabilities (logits) as to whether the sentence\n",
    "        # is negative (0) or positive (1).\n",
    "        logits = savedmodel.signatures[\"serving_default\"](attention_mask=feature_example['attention_mask'],\n",
    "                            input_ids=feature_example['input_ids'],\n",
    "                            token_type_ids=feature_example['token_type_ids'])['output_1']\n",
    "        print(f\"logits {logits}\")\n",
    "        \n",
    "        # It is more helpful to have the actual probabilities of success. The TensorFlow softmax \n",
    "        # function will convert the logits into probabilities.\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        \n",
    "        # At this point we have probabilities (probs) of whether the sentence is negative or positive. \n",
    "        # These probabilites (by definition) will always sum to 100%.\n",
    "        \n",
    "        # It would be better though if we could just report out which probability is higher. \n",
    "        # This is done with the argmax function.\n",
    "        \n",
    "        prediction = tf.math.argmax(probs, axis=1)\n",
    "\n",
    "        print(f\"probs {probs}\")\n",
    "        print(f\"prediction {prediction}\")\n",
    "\n",
    "        json_example = {\"SENTIMENT_PREDICTION\": str(prediction.numpy()[0])}\n",
    "        json_examples.append(json_example)\n",
    "\n",
    "    return json_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_example = {'idx': tf.constant(1, dtype=tf.int64), 'label': tf.constant(0, dtype=tf.int64) ,\n",
    "                    'sentence': tf.constant('This store is absolutely horrible and I hate it!!',\n",
    "                                            dtype=tf.string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(example, tokenizer, savedmodel):\n",
    "    \"\"\"\n",
    "\n",
    "    :param example: This is a single dictionary of tensors which contains a idx, a label, and a sentence\n",
    "    :return: The prediction in JSON format. 1 is positive, and 0 is negative.\n",
    "    \"\"\"\n",
    "    # The Transformers glue_convert_examples_to_features works well with datasets. \n",
    "    # It does not work well with a dictionary of examples. \n",
    "    ds = tf.data.Dataset.from_tensors(example)\n",
    "    \n",
    "    # Use the transformers library in order to convert an English sentence into something that \n",
    "    # BERT recognizes.\n",
    "    \n",
    "    # The conversion requires giving a label (even if we don't have one). The e-asiest way to get around this is to get around\n",
    "    # this is to assign a default label of zero when you don't have a label. \n",
    "    \n",
    "    feature_ds = glue_convert_examples_to_features(ds, tokenizer, max_length=512, task='sst-2')\n",
    "\n",
    "    feature_dataset = feature_ds.batch(64)\n",
    "    json_examples = predict_dataset(feature_dataset, savedmodel)\n",
    "\n",
    "    return json_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result = predict(negative_example, tokenizer, savedmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(example, tokenizer, savedmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = [row[1] for row in train_csv], [row[2] for row in train_csv]\n",
    "test_texts, test_labels =  [row[1] for row in test_csv], [row[2] for row in test_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_texts) ,  len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predicted = baseline_model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, baseline_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_confusion_matrix(baseline_predicted,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
